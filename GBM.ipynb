{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('data/train_music.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config = {\n",
    "    'folds': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_folds(data):\n",
    "    kfold = StratifiedKFold(n_splits=global_config['folds'], random_state=42)\n",
    "    folds_data = []\n",
    "    for ids in kfold.split(data.id.values, data.target.values):\n",
    "        train, test = ids\n",
    "        folds_data.append((data.iloc[train], data.iloc[test]))\n",
    "        \n",
    "    return folds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(train, val, config):\n",
    "    train_x = train.drop(columns=['target', 'id']).fillna(-9999)\n",
    "    train_y = train.target\n",
    "    \n",
    "    test_x = val.drop(columns=['target', 'id']).fillna(-9999)\n",
    "    test_y = val.target\n",
    "    \n",
    "    cols = list(train_x.columns)\n",
    "    \n",
    "    xgtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    \n",
    "    xgvalid = lgb.Dataset(test_x, label=test_y)\n",
    "    \n",
    "    \n",
    "    clf = lgb.train(config, \n",
    "                     xgtrain, \n",
    "                     valid_sets=[xgtrain, xgvalid], \n",
    "                     valid_names=['train','valid'],\n",
    "                     early_stopping_rounds=500,\n",
    "                     num_boost_round=1880,\n",
    "                     verbose_eval=50)\n",
    "\n",
    "    n_estimators = clf.best_iteration\n",
    "    predicted = clf.predict(test_x)\n",
    "    score = roc_auc_score(test_y, predicted)\n",
    "    prec = precision_score(test_y, (predicted > 0.5).astype(int))\n",
    "    f1 = f1_score(test_y, (predicted > 0.5).astype(int))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(test_y, (predicted > 0.5).astype(int)))\n",
    "    print(\"Report:\")\n",
    "    print(classification_report(test_y, (predicted > 0.5).astype(int)))\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = cols\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "\n",
    "    return {'score': score, 'model': clf, 'prec': prec, 'f1': f1, 'fold_importance': fold_importance_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test(models):\n",
    "#     test_lb = pd.read_csv('data/test_music.csv')\n",
    "    test_lb = pd.read_pickle('data/test.pkl')\n",
    "    test_lb = test_lb.drop(columns=['id'])\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        predict = model.predict(test_lb)\n",
    "        predictions.append(predict)\n",
    "    return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(predictions, score=\"Unknown\"):\n",
    "    sub = pd.read_csv('data/sample_submission_music.csv')\n",
    "    sub.prediction = predictions\n",
    "    sub.to_csv('s-%s.csv' % score, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_folds(folds, config):\n",
    "    models = []\n",
    "    auc = []\n",
    "    f1 = []\n",
    "    importances = []\n",
    "    for n, fold in enumerate(folds):\n",
    "        train_f, val_f = fold\n",
    "        print(\"Training on %s\" % str(train_f.shape))\n",
    "        result = train_lgbm(train_f, val_f, config)\n",
    "        \n",
    "        importance = result['fold_importance']\n",
    "        importance['fold'] = n\n",
    "        importances.append(importance)\n",
    "        \n",
    "        models.append(result['model'])\n",
    "        auc.append(result['score'])\n",
    "        f1.append(result['f1'])\n",
    "        print(\"Fold %s: %.4f, F1: %.4f, Precision: %.4f\" % (n, result['score'], result['f1'], result['prec']))\n",
    "    return models, {\n",
    "        'auc': np.mean(auc),\n",
    "        'importances': pd.concat(importances, sort=False),\n",
    "        'f1': np.mean(f1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = prepare_folds(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on (55999, 566)\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[50]\ttrain's auc: 0.851839\tvalid's auc: 0.81121\n",
      "[100]\ttrain's auc: 0.871398\tvalid's auc: 0.817691\n",
      "[150]\ttrain's auc: 0.885137\tvalid's auc: 0.820584\n",
      "[200]\ttrain's auc: 0.895614\tvalid's auc: 0.82129\n",
      "[250]\ttrain's auc: 0.904877\tvalid's auc: 0.822568\n",
      "[300]\ttrain's auc: 0.913546\tvalid's auc: 0.822419\n",
      "[350]\ttrain's auc: 0.921012\tvalid's auc: 0.821925\n",
      "[400]\ttrain's auc: 0.928083\tvalid's auc: 0.821716\n",
      "[450]\ttrain's auc: 0.934027\tvalid's auc: 0.821712\n",
      "[500]\ttrain's auc: 0.938964\tvalid's auc: 0.821656\n",
      "[550]\ttrain's auc: 0.944575\tvalid's auc: 0.820737\n",
      "[600]\ttrain's auc: 0.949691\tvalid's auc: 0.820396\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-ef55d6b64492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-103-3cb9d7b9f50d>\u001b[0m in \u001b[0;36mtrain_folds\u001b[0;34m(folds, config)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtrain_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fold_importance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-717134c22e71>\u001b[0m in \u001b[0;36mtrain_lgbm\u001b[0;34m(train, val, config)\u001b[0m\n\u001b[1;32m     19\u001b[0m                      \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                      \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1880\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                      verbose_eval=50)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programming/vodafone-music/.env/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programming/vodafone-music/.env/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1758\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1760\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1761\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "models, result = train_folds(folds, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8338, F1: 0.3633\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC: %.4f, F1: %.4f\" % (result['auc'], result['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "'num_iterations': 5000,\n",
    "'learning_rate': 0.1,\n",
    "'boosting_type': 'gbdt',\n",
    "'objective': 'binary',\n",
    "'metric':'auc',\n",
    "'num_leaves': 12,\n",
    "'max_depth': 4,\n",
    "'min_data_in_leaf': 500, \n",
    "# 'reg_alpha': 5,  # L1 regularization term on weights\n",
    "# 'reg_lambda': 5,\n",
    "'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "'scale_pos_weight': 9 # because training data is unbalanced \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = result['importances'].groupby(['feature'])\\\n",
    "                    .agg({'importance': 'mean'})\\\n",
    "                    .sort_values(by=\"importance\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lt',\n",
       " 'balance_sum',\n",
       " 'content_count_m1',\n",
       " 'content_count_m3',\n",
       " 'data_type_2_m1',\n",
       " 'days_exp',\n",
       " 'count_app_4',\n",
       " 'data_type_3_m1',\n",
       " 'os_category_is_my_vf',\n",
       " 'vol_app_7',\n",
       " 'data_type_1_m1',\n",
       " 'count_sms_source_4',\n",
       " 'vol_app_4',\n",
       " 'count_url_category_2',\n",
       " 'count_app_5',\n",
       " 'service_1_count',\n",
       " 'short_out_calls_part_m3',\n",
       " 'content_count_m2',\n",
       " 'all_cost_m1',\n",
       " 'data_type_2_m3',\n",
       " 'data_type_2_m2',\n",
       " 'all_count_m1',\n",
       " 'vol_app_5',\n",
       " 'paym_last_days',\n",
       " 'sms_in_count_m1',\n",
       " 'count_act_type_1',\n",
       " 'vol_app_1',\n",
       " 'short_in_calls_part_m1',\n",
       " 'is_my_vf_service_P_flag_m1',\n",
       " 'sms_in_count_m3',\n",
       " 'manufacturer_category_is_my_vf',\n",
       " 'income_brnd_cont_m1',\n",
       " 'short_out_calls_part_m1',\n",
       " 'paym_sum_m1',\n",
       " 'act_days_count_m3',\n",
       " 'all_cost_m3',\n",
       " 'data_type_3_m2',\n",
       " 'paym_el_sum_m3',\n",
       " 'count_url_category_10',\n",
       " 'voice_omo_out_day_rest_cost_m3',\n",
       " 'count_act_type_7',\n",
       " 'short_in_calls_part_m3',\n",
       " 'manufacturer_category_service_P_flag_m3',\n",
       " 'voice_onnet_in_day_work_dur_m3',\n",
       " 'paym_sum_m3',\n",
       " 'count_app_1',\n",
       " 'voice_in_uniq_count_m1',\n",
       " 'sms_in_count_m2',\n",
       " 'paym_sum_m2',\n",
       " 'voice_onnet_in_night_rest_dur_m1']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(importance.head(50).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = eval_test(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepare_submission(test_target, \"AUC_%.4f_F1_%.4f\" % (result['auc'], result['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(params):\n",
    "#     params = {\n",
    "#         'num_iterations': 1000,\n",
    "#         'learning_rate': 0.1,\n",
    "#         'boosting_type': 'gbdt',\n",
    "#         'objective': 'binary',\n",
    "#         'metric':'auc',\n",
    "#         'num_leaves': int(params['num_leaves']),\n",
    "#         'max_depth': int(params['max_depth']),\n",
    "#         'reg_alpha': int(params['reg_alpha']),  # L1 regularization term on weights\n",
    "#         'reg_lambda': int(params['reg_lambda']),\n",
    "#         'min_child_samples': int(params['min_child_samples']),  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "#         'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "#         'subsample': float(params['subsample']),  # Subsample ratio of the training instance.\n",
    "#         'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "#         'colsample_bytree': float(params['colsample_bytree']),  # Subsample ratio of columns when constructing each tree.\n",
    "#         'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "#         'scale_pos_weight': 9 # because training data is unbalanced \n",
    "#     }\n",
    "#     models, result = train_folds(folds, params)\n",
    "#     return -result['auc']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space = {\n",
    "#     'num_leaves': hp.quniform('num_leaves', 4, 24, 1),\n",
    "#     'max_depth': hp.quniform('max_depth', 2, 8, 1),\n",
    "#     'reg_alpha': hp.quniform('reg_alpha', 1, 100, 2),\n",
    "#     'reg_lambda': hp.quniform('reg_lambda', 1, 100, 2),\n",
    "#     'min_child_samples': hp.quniform('min_child_samples', 100, 5000, 100),\n",
    "#     'subsample': hp.quniform('subsample', 0.4, 1, 0.1),\n",
    "#     'colsample_bytree': hp.quniform('colsample_bytree', 0.4, 1, 0.1),\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# best = fmin(fn=objective,\n",
    "#             space=space,\n",
    "#             algo=tpe.suggest,\n",
    "#             max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
